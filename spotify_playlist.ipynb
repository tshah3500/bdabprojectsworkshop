{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ece140b",
   "metadata": {},
   "source": [
    "$\\Large \\text{Projects Technical Interview Code Workshop}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import kagglehub\n",
    "import random\n",
    "import string\n",
    "import spotipy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0c327",
   "metadata": {},
   "source": [
    "$\\text{Making the dataset - we're not going to go over this in our workshop, but you should definitly check it out at some point.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"sgoutami/spotify-streaming-history\")\n",
    "path = path + \"/spotify_history.csv\"\n",
    "\n",
    "raw_data = pd.read_csv(path)\n",
    "raw_data['ts'] = pd.to_datetime(raw_data['ts'])\n",
    "\n",
    "load_dotenv()\n",
    "client_id = os.getenv(\"CLIENT_ID_2\")\n",
    "client_secret = os.getenv(\"CLIENT_SECRET_2\")\n",
    "auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7492f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_id(length):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    random_string = ''.join(random.choice(characters) for _ in range(length))\n",
    "    return random_string\n",
    "\n",
    "def assign_user_ids(df, user_id_labels):\n",
    "    if len(user_id_labels) > len(df):\n",
    "        user_id_labels = user_id_labels[:len(df)]\n",
    "        df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "        df['userId'] = user_id_labels\n",
    "        return df\n",
    "    temp_user_id = generate_user_id(6)\n",
    "    tracks = round(np.random.normal(loc=100, scale=20))\n",
    "    user_id_labels.extend([temp_user_id for _ in range(tracks)])\n",
    "    return assign_user_ids(df, user_id_labels)\n",
    "\n",
    "def get_song_metadata(uris, sp):\n",
    "    tracks_response = sp.tracks(uris)[\"tracks\"]\n",
    "    artist_ids = list({artist[\"id\"] for track in tracks_response for artist in track[\"artists\"]})\n",
    "    artists_response = sp.artists(artist_ids)[\"artists\"]\n",
    "    artist_genre_map = {artist[\"id\"]: artist.get(\"genres\", \"\") for artist in artists_response}\n",
    "    metadata_list = []\n",
    "    for track in tracks_response:\n",
    "        primary_artist = track[\"artists\"][0]\n",
    "        genres = artist_genre_map.get(primary_artist[\"id\"], [])\n",
    "        genre = genres[0] if genres else \"\" \n",
    "\n",
    "        metadata = {\n",
    "            \"track_name\": track[\"name\"],\n",
    "            \"artists\": [artist[\"name\"] for artist in track[\"artists\"]],\n",
    "            \"album\": track[\"album\"][\"name\"],\n",
    "            \"release_date\": track[\"album\"][\"release_date\"],\n",
    "            \"genres\": genre,\n",
    "            \"duration_ms\": track[\"duration_ms\"],\n",
    "            \"popularity\": track[\"popularity\"],\n",
    "            \"explicit\": track[\"explicit\"],\n",
    "            \"uri\": track[\"uri\"]\n",
    "        }\n",
    "        metadata_list.append(metadata)\n",
    "    return metadata_list\n",
    "\n",
    "new_dataset = assign_user_ids(raw_data, [])\n",
    "new_dataset = new_dataset[[\"userId\", \"spotify_track_uri\", \"track_name\", \"ms_played\", \"ts\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = new_dataset['spotify_track_uri'].unique().tolist()\n",
    "track_information = []\n",
    "\n",
    "for start in range(0, len(tracks), 25):\n",
    "    stop = min(start + 25, len(tracks))\n",
    "    if start % 1000 == 0 and start != 0:\n",
    "        print(f\"Processed {start} songs. Pausing for 2 minutes to avoid going over Spotify's rate limits.\")\n",
    "        time.sleep(120) \n",
    "    uris = tracks[start:stop] \n",
    "    try:\n",
    "        temp_info = get_song_metadata(uris, sp)\n",
    "    except Exception as e:\n",
    "        print(f\"Didn't process batch {start} to {stop} due to error: {e}.\")\n",
    "        temp_info = []\n",
    "    track_information.extend(temp_info)\n",
    "    \n",
    "saved_tracks_df = pd.DataFrame(track_information)\n",
    "saved_tracks_df.to_csv(\"spotify_song_metadata\", index=False)\n",
    "new_dataset.to_csv(\"spotify_streaming_history.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2430f",
   "metadata": {},
   "source": [
    "$\\text{Let's start by exploring our datasets and cleaning them.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_history = pd.read_csv(\"spotify_streaming_history.csv\")\n",
    "song_metadata = pd.read_csv(\"spotify_song_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed432820",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_history.sort_values(by=['ts'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6071da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_metadata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c33e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_metadata[\"artists\"] = song_metadata[\"artists\"].apply(lambda x: eval(x)[0])\n",
    "song_metadata['uri'] = song_metadata['uri'].str.replace(\"spotify:track:\", \"\")\n",
    "song_metadata = song_metadata[['artists', 'album', 'release_date', 'genres', 'duration_ms', 'popularity', 'uri']]\n",
    "streaming_history = streaming_history.merge(song_metadata, left_on='spotify_track_uri', right_on='uri', how='left').drop(columns=['uri'])\n",
    "song_database = streaming_history.copy()\n",
    "streaming_history = streaming_history[['userId', 'ms_played', 'genres', 'duration_ms', 'popularity', 'release_date']].dropna()\n",
    "streaming_history['release_date'] = streaming_history['release_date'].astype('datetime64[ns]').dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894ce98f",
   "metadata": {},
   "source": [
    "$\\text{Next, lets one-hot encode the genres, release dates, and popularity, so we can group by user!}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_history = pd.get_dummies(streaming_history, columns=['genres']).rename(columns=lambda x: x.replace(\"genres_\", \"\"))\n",
    "\n",
    "year_bins = np.arange(1920, 2030, 10)  \n",
    "popularity_bins = np.arange(0, 110, 25)\n",
    "labels = [f\"{start}s\" for start in year_bins[:-1]]\n",
    "\n",
    "streaming_history[\"decade\"] = pd.cut(streaming_history[\"release_date\"], bins=year_bins, labels=labels, right=False)\n",
    "streaming_history[\"popularity_bin\"] = pd.cut(streaming_history[\"popularity\"], bins=popularity_bins, right=False)\n",
    "\n",
    "streaming_history = pd.get_dummies(streaming_history, columns=[\"decade\"], prefix=\"\", prefix_sep=\"\")\n",
    "streaming_history = pd.get_dummies(streaming_history, columns=[\"popularity_bin\"], prefix=\"popularity_\", prefix_sep=\"\")\n",
    "streaming_history.drop(columns=['release_date', 'popularity'], inplace=True)\n",
    "\n",
    "streaming_history = streaming_history[streaming_history['ms_played']/streaming_history['duration_ms'] > 0.7]\n",
    "song_database = song_database[song_database['ms_played']/song_database['duration_ms'] > 0.7]\n",
    "user_characteristics = streaming_history.groupby('userId').agg(np.mean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d46487",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37222afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b1032",
   "metadata": {},
   "source": [
    "$\\text{Now that we have user characteristics, lets begin choosing a model to find the people who have the most similar listening patterns to any given user.}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bc6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First approach: KNN.\n",
    "def euclidean_distance(user):\n",
    "    return lambda x: np.sqrt(np.sum((x - user) ** 2))\n",
    "\n",
    "def knn(user_id, k = 30):\n",
    "    user_vector = np.array(user_characteristics[user_characteristics['userId'] == user_id])[0][3:]\n",
    "    distance_func = euclidean_distance(user_vector)\n",
    "    user_characteristics['distance'] = user_characteristics.apply(lambda row: distance_func(np.array(row[3:])), axis=1)\n",
    "    nearest_neighbors = user_characteristics[user_characteristics['userId'] != user_id].nsmallest(k, 'distance')\n",
    "    return nearest_neighbors['userId'].tolist()\n",
    "\n",
    "def generate_playlist(user_id, num_songs=30):\n",
    "    similar_users = knn(user_id, 100)\n",
    "    similar_users_songs = song_database[song_database['userId'].isin(similar_users)]\n",
    "    \n",
    "    #Random Approach\n",
    "    #recommended_songs = similar_users_songs.sample(n=num_songs, weights='ms_played', replace=False)\n",
    "    \n",
    "    #Deterministic Approach\n",
    "    song_counts = similar_users_songs.value_counts('track_name')\n",
    "    similar_users_songs ['counts'] = similar_users_songs ['track_name'].map(song_counts)\n",
    "    recommended_songs = similar_users_songs .sort_values(by=['counts'], ascending=False).drop_duplicates(subset=['track_name']).head(num_songs)\n",
    "    \n",
    "    return recommended_songs[['track_name', 'artists', 'counts']]\n",
    "\n",
    "generate_playlist('1RfKDh', num_songs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second approach: Clustering with KMeans (PREFERRED).\n",
    "def kMeans(k, df):\n",
    "    X = df.iloc[:, 3:] \n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    df['cluster'] = kmeans.fit_predict(X)\n",
    "    return df\n",
    "\n",
    "def plot_elbow_method(df, max_k=15):\n",
    "    X = df.iloc[:, 3:] \n",
    "    wcss = []\n",
    "    for k in range(1, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, max_k + 1), wcss, marker='o')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.xlabel('Number of clusters (k)')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.xticks(range(1, max_k + 1))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def generate_playlist_kmeans(user_id, cluster_characteristics, num_songs=30):\n",
    "    user_cluster = cluster_characteristics[cluster_characteristics['userId'] == user_id]['cluster'].values[0]\n",
    "    cluster_users = cluster_characteristics[cluster_characteristics['cluster'] == user_cluster]['userId'].tolist()\n",
    "    cluster_users_songs = song_database[song_database['userId'].isin(cluster_users)]\n",
    "    \n",
    "    #Random Approach\n",
    "    #recommended_songs = cluster_users_songs.sample(n=num_songs, weights='ms_played', replace=False)\n",
    "    \n",
    "    #Deterministic Approach\n",
    "    song_counts = cluster_users_songs.value_counts('track_name')\n",
    "    cluster_users_songs ['counts'] = cluster_users_songs ['track_name'].map(song_counts)\n",
    "    recommended_songs = cluster_users_songs .sort_values(by=['counts'], ascending=False).drop_duplicates(subset=['track_name']).head(num_songs)\n",
    "    \n",
    "    return recommended_songs[['track_name', 'artists', 'counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b78fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elbow_method(user_characteristics, max_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_characteristics = kMeans(5, user_characteristics)\n",
    "generate_playlist_kmeans('1RfKDh', cluster_characteristics, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
